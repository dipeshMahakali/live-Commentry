<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Parthasarathi - Live Universal Partner</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        .glass { background: rgba(15, 23, 42, 0.8); backdrop-filter: blur(12px); border: 1px solid rgba(255, 255, 255, 0.1); }
        .glow { box-shadow: 0 0 20px rgba(59, 130, 246, 0.5); }
        .jarvis-orb { width: 150px; height: 150px; border-radius: 50%; background: radial-gradient(circle, #3b82f6 0%, #1d4ed8 70%, #1e1b4b 100%); animation: pulse 2s infinite; }
        @keyframes pulse { 0% { transform: scale(1); opacity: 0.8; } 50% { transform: scale(1.05); opacity: 1; } 100% { transform: scale(1); opacity: 0.8; } }
    </style>
</head>
<body class="bg-[#020617] text-slate-100 font-sans min-h-screen flex flex-col items-center justify-center p-6">

    <!-- JARVIS ORB -->
    <div class="jarvis-orb glow mb-8 flex items-center justify-center">
        <div class="text-xs font-bold tracking-widest text-blue-200">PARTHASARATHI</div>
    </div>

    <h1 class="text-3xl font-bold mb-2 tracking-tight">World's Best Life-Long Partner</h1>
    <p class="text-slate-400 mb-8 italic">"Bhai, I am watching your screen live. Tension mat lo."</p>

    <!-- CONTROL PANEL -->
    <div class="glass p-8 rounded-2xl w-full max-w-md flex flex-col gap-4">
        <button id="startBtn" class="bg-blue-600 hover:bg-blue-500 py-3 rounded-xl font-bold transition-all transform hover:scale-105">
            ðŸš€ Wake Up (Share Screen)
        </button>
        
        <div class="flex flex-col gap-2">
            <label class="text-xs text-slate-500 uppercase font-bold">Groq API Key</label>
            <input type="password" id="apiKey" placeholder="gsk_..." class="bg-slate-900 border border-slate-700 p-3 rounded-lg focus:outline-none focus:border-blue-500">
        </div>

        <div id="status" class="text-center text-sm text-blue-400 font-mono mt-4">Status: Sleeping...</div>
    </div>

    <!-- DEBUG CONSOLE -->
    <div class="mt-8 w-full max-w-2xl bg-black border border-slate-800 rounded-lg p-4 font-mono text-xs overflow-y-auto max-h-40" id="debugConsole">
        <div class="text-blue-500">[System] Diagnostics initialized...</div>
    </div>

    <!-- LOGS -->
    <div id="output" class="mt-4 text-sm text-slate-400 max-w-2xl text-center"></div>

    <script>
        const startBtn = document.getElementById('startBtn');
        const apiKeyInput = document.getElementById('apiKey');
        const statusDiv = document.getElementById('status');
        const outputDiv = document.getElementById('output');
        const debugConsole = document.getElementById('debugConsole');

        let screenStream = null;
        let goldDataset = JSON.parse(localStorage.getItem('saved_gold_data') || '[]');
        let recognition = null;
        let lastUserSpeech = "";
        let isActive = false;

        function logDebug(msg, color = "text-slate-500") {
            const div = document.createElement('div');
            div.className = color;
            div.innerText = `[${new Date().toLocaleTimeString()}] ${msg}`;
            debugConsole.prepend(div);
            console.log(`[Partha] ${msg}`);
        }

        // Check protocol
        if (window.location.protocol === 'file:') {
            logDebug("âš ï¸ WARNING: Running via file:// protocol. Microphone will be BLOCKED by browser. Please use a local server (e.g., Live Server or python -m http.server).", "text-orange-400");
        }

        if (goldDataset.length > 0) {
            logDebug(`Restored ${goldDataset.length} previous interactions.`, "text-green-500");
        }
        // JARVIS Initialization
        startBtn.onclick = async () => {
            logDebug("Starting Environment Audit...");
            
            // diagnostic check
            if (!window.isSecureContext) {
                logDebug("ðŸš¨ SECURE CONTEXT MISSING: Browser blocks Cam/Mic/Screen unless using 'localhost' or 'https'.", "text-red-500");
                return alert("Security Error: Please access via http://localhost:PORT or use HTTPS.");
            }
            if (!navigator.mediaDevices || !navigator.mediaDevices.getDisplayMedia) {
                logDebug("ðŸš¨ API MISSING: Your browser doesn't support Screen Sharing (getDisplayMedia). Use Chrome/Edge/Firefox.", "text-red-500");
                return alert("Browser Error: API not supported.");
            }

            const key = apiKeyInput.value.trim() || localStorage.getItem('sarthi_key');
            if(!key) return alert("Bhai, Groq API Key dalo pehle!");
            localStorage.setItem('sarthi_key', key);

            try {
                logDebug("Asking for screen capture permission...");
                screenStream = await navigator.mediaDevices.getDisplayMedia({ 
                    video: { frameRate: 5 }, // Low frame rate to save bandwidth/CPU
                    audio: false
                });
                
                logDebug("Screen Capture Ready!", "text-green-500");
                statusDiv.innerText = "Status: JARVIS ACTIVE";
                startBtn.classList.add('hidden');
                isActive = true;

                const downloadBtn = document.createElement('button');
                downloadBtn.innerText = "ðŸ“¥ Download Gold Dataset";
                downloadBtn.className = "bg-green-600 p-3 rounded-xl mt-4 font-bold w-full transition-all hover:bg-green-500 shadow-lg";
                downloadBtn.onclick = downloadData;
                startBtn.parentElement.appendChild(downloadBtn);

                initVoice();
                startLifeCycle(key);
            } catch (err) {
                logDebug(`Launch Failed: ${err.message}`, "text-red-500");
                statusDiv.innerText = "Status: Startup Error";
            }
        };

        function initVoice() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (SpeechRecognition) {
                try {
                    recognition = new SpeechRecognition();
                    recognition.continuous = true;
                    recognition.interimResults = false;
                    recognition.lang = 'hi-IN';

                    recognition.onresult = (event) => {
                        const speech = event.results[event.results.length - 1][0].transcript;
                        lastUserSpeech = speech;
                        logDebug(`User said: "${speech}"`, "text-yellow-400");
                    };

                    recognition.onerror = (err) => {
                        logDebug(`Mic Error: ${err.error}. (Tip: Use Chrome + Localhost)`, "text-red-400");
                        if (err.error === 'not-allowed') {
                            logDebug("Microphone permission denied. Restart in browser settings.", "text-red-500");
                        }
                    };

                    recognition.onend = () => {
                        if (isActive) {
                            setTimeout(() => {
                                try { recognition.start(); } catch(e) {}
                            }, 2000);
                        }
                    };

                    recognition.start();
                    logDebug("Mic listening started.", "text-blue-400");
                } catch (e) {
                    logDebug(`STT Init Error: ${e.message}`, "text-red-500");
                }
            } else {
                logDebug("Hinglish Speech Recognition not supported in this browser.", "text-red-500");
            }
        }

        async function startLifeCycle(apiKey) {
            const video = document.createElement('video');
            video.srcObject = screenStream;
            await video.play();
            logDebug("Universal Consciousness Active. Monitoring Science, Logic, and Story.");

            setInterval(async () => {
                if (!isActive) return;

                const canvas = document.createElement('canvas');
                canvas.width = 1120;
                canvas.height = 630;
                const ctx = canvas.getContext('2d');
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
                const frameBase64 = canvas.toDataURL('image/jpeg', 0.5);

                statusDiv.innerText = "Status: Analyzing Context...";
                
                try {
                    const response = await fetch("https://api.groq.com/openai/v1/chat/completions", {
                        method: "POST",
                        headers: {
                            "Authorization": `Bearer ${apiKey}`,
                            "Content-Type": "application/json"
                        },
                        body: JSON.stringify({
                            model: "llama-3.2-90b-vision-preview", 
                            messages: [
                                {
                                    role: "user",
                                    content: [
                                        { type: "text", text: `Persona: You are Parthasarathi, a brilliant, witty, and deeply intuitive female partner. 
                                              Nature: You analyze the screen like a genius (Science, Code, Gaming, or Cinema). 
                                              Vibe: Talk like a real girl who is your partner-in-crime. Use natural Hinglish.
                                              Goal: Don't repeat what's on screen. Connect the dots. If it's science, explain the 'Why'. If it's a story, predict the plot. If it's a game, find the flaw.
                                              Slang: Use 'Yaar', 'Bhai', 'Gazab', 'Suno', 'Dekho'.
                                              Constraint: Keep it under 20 words. No robot talk.` },
                                        { type: "image_url", image_url: { url: frameBase64 } }
                                    ]
                                }
                            ],
                            max_tokens: 80
                        })
                    });

                    const data = await response.json();
                    const aiReply = data.choices[0]?.message?.content;
                    if (!aiReply) throw new Error("Connection failed");

                    logDebug(`Partha: "${aiReply}"`, "text-pink-400");
                    statusDiv.innerText = "Status: Waking Up...";
                    speak(aiReply);

                    goldDataset.push({
                        timestamp: new Date().toISOString(),
                        context: "Universal Analysis",
                        ai_response: aiReply
                    });
                    localStorage.setItem('saved_gold_data', JSON.stringify(goldDataset));
                } catch (err) {
                    logDebug(`Brain Sync Error: ${err.message}`, "text-red-500");
                }
            }, 12000);
        }

        function speak(text) {
            const utterance = new SpeechSynthesisUtterance(text);
            const voices = window.speechSynthesis.getVoices();
            
            // Priority: Female high-quality voices
            const femaleVoice = voices.find(v => (v.name.includes('Google') || v.name.includes('Neural')) && v.lang.includes('hi')) 
                               || voices.find(v => v.name.includes('Female') || v.lang.includes('hi'));
            
            if (femaleVoice) utterance.voice = femaleVoice;
            utterance.lang = 'hi-IN';
            utterance.pitch = 1.2; // Makes it feel more feminine/friendly
            utterance.rate = 1.0;
            window.speechSynthesis.speak(utterance);
        }

        function downloadData() {
            if (goldDataset.length === 0) return alert("Bhai, data toh hone do!");
            const blob = new Blob([JSON.stringify(goldDataset, null, 2)], { type: 'application/json' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = `partha_real_data_${Date.now()}.json`;
            a.click();
        }
    </script>
</body>
</html>
